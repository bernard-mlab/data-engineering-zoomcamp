{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import gzip\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x7fabebb5d490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connection to postgres with credentials\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "engine.connect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Green Taxi Trips Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "green_trip_data_csv = \"./data/green_tripdata_2019-01.csv.gz\"\n",
    "\n",
    "green_trip_data_df_iter = pd.read_csv(green_trip_data_csv, compression='gzip', iterator=True, chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted chunk 1, with 100000 records... took 7.600 seconds\n",
      "inserted chunk 2, with 100000 records... took 7.416 seconds\n",
      "inserted chunk 3, with 100000 records... took 7.192 seconds\n",
      "inserted chunk 4, with 100000 records... took 7.285 seconds\n",
      "inserted chunk 5, with 100000 records... took 7.863 seconds\n",
      "inserted chunk 6, with 100000 records... took 8.232 seconds\n",
      "inserted chunk 7, with 30918 records... took 2.842 seconds\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m t_start \u001b[39m=\u001b[39m time()\n\u001b[1;32m      5\u001b[0m \u001b[39m# read next chunk of records\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m green_trip_data_df \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(green_trip_data_df_iter)\n\u001b[1;32m      7\u001b[0m records \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(green_trip_data_df)\n\u001b[1;32m      8\u001b[0m \u001b[39m# clean up datetime column\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_data_eng/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1698\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1696\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   1697\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1698\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_chunk()\n\u001b[1;32m   1699\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m   1700\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_data_eng/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1810\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1808\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1809\u001b[0m     size \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnrows \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_currow)\n\u001b[0;32m-> 1810\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nrows\u001b[39m=\u001b[39;49msize)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_data_eng/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     (\n\u001b[1;32m   1775\u001b[0m         index,\n\u001b[1;32m   1776\u001b[0m         columns,\n\u001b[1;32m   1777\u001b[0m         col_dict,\n\u001b[0;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1779\u001b[0m         nrows\n\u001b[1;32m   1780\u001b[0m     )\n\u001b[1;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_data_eng/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 230\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    231\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/miniconda3/envs/py310_data_eng/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:833\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# clean up data and loading to postgres\n",
    "chunk = 0\n",
    "while True:\n",
    "    t_start = time()\n",
    "    # read next chunk of records\n",
    "    green_trip_data_df = next(green_trip_data_df_iter)\n",
    "    records = len(green_trip_data_df)\n",
    "    # clean up datetime column\n",
    "    green_trip_data_df['lpep_pickup_datetime'] = pd.to_datetime(green_trip_data_df['lpep_pickup_datetime'])\n",
    "    green_trip_data_df['lpep_dropoff_datetime'] = pd.to_datetime(green_trip_data_df['lpep_dropoff_datetime'])\n",
    "    # load to postgres\n",
    "    green_trip_data_df.to_sql(name='green_trip_data', con=engine, if_exists='append')\n",
    "    t_end = time()\n",
    "    chunk += 1\n",
    "    print(f\"inserted chunk {chunk}, with {records} records... took {(t_end-t_start):.3f} seconds\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NY Taxi Data mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file\n",
    "taxi_zone_csv = \"./data/taxi+_zone_lookup.csv\"\n",
    "taxi_zone_df = pd.read_csv(taxi_zone_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted taxi zone, with 265 records... took 0.023 seconds\n"
     ]
    }
   ],
   "source": [
    "# upload mapping to postgres\n",
    "t_start = time()\n",
    "records = len(taxi_zone_df)\n",
    "# load to postgres\n",
    "taxi_zone_df.to_sql(name='dim_taxi_zone', con=engine, if_exists='replace')\n",
    "t_end = time()\n",
    "print(f\"inserted taxi zone, with {records} records... took {(t_end-t_start):.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get schema from df to for SQL table creation\n",
    "print(pd.io.sql.get_schema(green_trip_data_df, name='green_trip_data', con=engine))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_data_eng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "310fad8623c747d9dc79896b68d4b342eac8efb0612a1c6434bbdcd1abf690ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
